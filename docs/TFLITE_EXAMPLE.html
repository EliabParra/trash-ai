<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TrashAI - TFLite Web Demo</title>
    <!-- Import TensorFlow.js and TFLite backend -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-cpu"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/tf-tflite.min.js"></script>
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .container { text-align: center; }
        #preview { max-width: 300px; margin: 20px auto; display: block; }
        #result { font-weight: bold; font-size: 1.2em; margin-top: 20px; }
        button { padding: 10px 20px; cursor: pointer; }
    </style>
</head>
<body>
    <div class="container">
        <h1>TrashAI Classifier (TFLite)</h1>
        <input type="file" id="imageInput" accept="image/*">
        <img id="preview" src="#" alt="Image preview" style="display:none;">
        <button onclick="runInference()">Classify Waste</button>
        <div id="result">Waiting for image...</div>
    </div>

    <script>
        // TrashNet Classes (Alphabetical order from directory structure)
        const CLASSES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash'];
        let tfliteModel = null;

        // Load model on startup
        async function loadModel() {
            try {
                console.log("Loading model...");
                // Note: You must serve this file via a web server (http-server, live-server, etc.)
                // Browsers block local file access (CORS).
                tfliteModel = await tflite.loadTFLiteModel('./models/trashnet_model.tflite');
                console.log("Model loaded!");
                document.getElementById('result').innerText = "Model Ready. Select an image.";
            } catch (e) {
                console.error(e);
                document.getElementById('result').innerText = "Error loading model. Check console.";
            }
        }

        // Handle image preview
        document.getElementById('imageInput').addEventListener('change', function(e) {
            const reader = new FileReader();
            reader.onload = function(event) {
                const img = document.getElementById('preview');
                img.src = event.target.result;
                img.style.display = 'block';
            }
            reader.readAsDataURL(e.target.files[0]);
        });

        // Run inference
        async function runInference() {
            if (!tfliteModel) {
                alert("Model not loaded yet!");
                return;
            }
            
            const imgElement = document.getElementById('preview');
            if (!imgElement.src || imgElement.src === '#') {
                alert("Please select an image first.");
                return;
            }

            // 1. Preprocess Image
            // MobileNetV2 expects 224x224 input
            // Our training used rescale=1./255, so pixels should be commonly [0, 1]
            // However, verify if your specific model expects [-1, 1] or [0, 1]. 
            // Based on data_loader.py, it's [0, 1].
            
            const inputTensor = tf.tidy(() => {
                let img = tf.browser.fromPixels(imgElement);
                img = tf.image.resizeBilinear(img, [224, 224]); // Resize
                img = tf.expandDims(img, 0); // Add batch dimension: [1, 224, 224, 3]
                img = tf.cast(img, 'float32');
                img = img.div(tf.scalar(255)); // Normalize to [0, 1]
                return img;
            });

            // 2. Predict
            const outputTensor = tfliteModel.predict(inputTensor);
            const probabilities = await outputTensor.data();
            
            // 3. Interpret Results
            const maxScoreIndex = probabilities.indexOf(Math.max(...probabilities));
            const predictedClass = CLASSES[maxScoreIndex];
            const confidence = (probabilities[maxScoreIndex] * 100).toFixed(2);
            
            document.getElementById('result').innerText = 
                `Prediction: ${predictedClass.toUpperCase()} (${confidence}%)`;

            // Cleanup
            inputTensor.dispose();
            outputTensor.dispose();
        }

        loadModel();
    </script>
</body>
</html>
